{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dApheqXqV-Tf"
      },
      "source": [
        "# Data preprocessing: more art than science?\n",
        "## Written by Nadia Blostein and Cesare Spinoso"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-R_4TaoV-Th"
      },
      "source": [
        "## Contents of this notebook:\n",
        "<ol>\n",
        "<li>Load and examine your data</li>\n",
        "<li>Merging two dataframes</li>\n",
        "<li>Removing features that you do not need</li>\n",
        "<li>Making your data machine-readable</li>\n",
        "<li>Handling not available (NA) and inf data</li>\n",
        "<li>Data visualization</li>\n",
        "<li>2D image visualization</li>\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup\n",
        "Fetch the dataset that you'll be working with throughout this assignment.\n"
      ],
      "metadata": {
        "id": "-JrpQkXhYLKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/NadiaBlostein/Open-Access-HCP-Data.git"
      ],
      "metadata": {
        "id": "3PiZxGN8YY7t",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Examine your directory structure with the `ls` command. To invoke this command from a jupyter notebook in Google Colab, the `ls` command should be preceded with `!`. "
      ],
      "metadata": {
        "id": "1L4WX4C_Synu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "-1foEjAGSguZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change the working directory of the notebook to within the folder `Open-Access-HCP-Data`. The `cd` command should be preceded with `%`.\n"
      ],
      "metadata": {
        "id": "dVQjjmXWSHvo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Open-Access-HCP-Data \n",
        "!ls"
      ],
      "metadata": {
        "id": "qW23_nXkZRKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this assignment, we will be working with data from the Human Connectome Project (HCP). You can read more about the data [here](https://github.com/NadiaBlostein/McMedHacks2022_Prep_Week_3_Assignment#readme). Specifically, you will preprocess `.csv` (in the `HCP_csv_data` folder) and `.png` files (in the `HCP_2D_slices_MRI_data` folder)."
      ],
      "metadata": {
        "id": "nYL3sxnFSyUV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls HCP_2D_slices_MRI_data"
      ],
      "metadata": {
        "id": "_KmjJboZTW1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls HCP_csv_data "
      ],
      "metadata": {
        "id": "vMJ-aUYRTZvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tG2oM0BjV-Ti"
      },
      "source": [
        "# 1. Load and examine your data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uMQIjPJV-Tj"
      },
      "source": [
        "### Preliminary examination of your data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "lkzkrh-oV-Tj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv(\"HCP_csv_data/unrestricted_HCP_behavioral.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVkqozdRV-Tk"
      },
      "source": [
        "**Question 1:** How many subjects (rows) and features (columns) do you have? PS: you cannot always assume that your subjects are rows and features are columns, and sometimes there may be rows with useless information that you need to remove."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eXqY0np7V-Tk",
        "collapsed": true,
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "print(f\"Num subjects: {df.shape[0]}\")\n",
        "print(f\"Num features: {df.shape[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feel free to examine your data frame in the empty code cell below. Examples of valuable commands for a preliminary look at one's data frame: `df.info()`, `df.describe()`, `df.columns()`, `df.head()`, `df.tail`."
      ],
      "metadata": {
        "id": "7z5Y3exuzhd-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we will select the `Gender` column to count how many instances we have of each value."
      ],
      "metadata": {
        "id": "vR_zFqfAz7j7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VnKocnwxV-Tn"
      },
      "outputs": [],
      "source": [
        "print(f\"unique values of column: {df['Gender'].unique()}\") # prints list of unique values in a feature / column\n",
        "print(f\"\\nvalue counts of column:\\n{df['Gender'].value_counts()}\") # counts how many times each unique value in a feature / column occurs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 2:** Is there another way to count how many males and females are in this dataset? "
      ],
      "metadata": {
        "id": "_d4xPY2Wi5j0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "print(f\"Number females: {len(df[df['Gender']=='F'])}\")\n",
        "print(f\"Number males: {len(df[df['Gender']=='M'])}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Eqzz3cCx0_nS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 3:** Display only the rows associated with female subjects."
      ],
      "metadata": {
        "id": "_KU-J4PhjZWd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3W5g75VV-Tn",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "df[df['Gender']==\"F\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgl2Bg-zV-Tn"
      },
      "source": [
        "### A side note on documentation\n",
        "Woah! So many columns and abbreviations! What do they all mean? Make sure you know where your [dataset's documentation](https://wiki.humanconnectome.org/display/PublicData/HCP-YA+Data+Dictionary-+Updated+for+the+1200+Subject+Release#HCPYADataDictionaryUpdatedforthe1200SubjectRelease-Instrument:Demographics) is.\n",
        "\n",
        "Unfortunately, thorough documentation is not always available. Some data types are also very field-specific and require the help of experts, which is part of what makes machine learning so wonderfully interdisciplinary.\n",
        "\n",
        "Let's take a look at what features we have here:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)"
      ],
      "metadata": {
        "id": "yLwc_rf0j19-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 4:** The script above is not printing ALL of the columns... How do we fix that to be able to see all the features in the dataset?"
      ],
      "metadata": {
        "id": "aMyKyvPtj9cy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3AWelNh_V-To",
        "cellView": "form",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "for col in df.columns: print(col)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVZ3jtdSV-To"
      },
      "source": [
        "### Selecting the features you want to work with:\n",
        "As you saw above, this dataframe has 499 features. Often, you will only want to work with a subset of the features of a dataframe, so you will have to create a new dataframe with this subset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBMC8C2QV-To"
      },
      "outputs": [],
      "source": [
        "basics = ['Subject','Gender','Age','PSQI_BedTime']\n",
        "df[basics]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mve4NaXUV-To"
      },
      "source": [
        "Let's also add all of some cognitive variables to the mix! Specifically, we'll select the measures related to fluid intelligence (they start with `PMAT` for Penn Matrix Test) and impulsivity (they start with `DDisc` for Delay Discounting)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "TSd4Fw-xV-To"
      },
      "outputs": [],
      "source": [
        "cognition = ['Subject','Gender','Age','PSQI_BedTime']\n",
        "for col in df.columns:\n",
        "    if (col.find(\"PMAT\")!=-1 or col.find(\"DDisc\")!=-1):\n",
        "        cognition.append(col)\n",
        "print(f\"List of variables we will be looking at: {cognition}\") # PS: f-strings will be very useful for you in your Python journey!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TyvOYGOV-To"
      },
      "source": [
        "**Question 5:** Now that we made a list of all of the features we want to examine, select this subset of our data and make it a separate dataframe called `df_cognition`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6cc_jyXLV-Tp",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "df_cognition = df[cognition]\n",
        "df_cognition.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Crko0pPjV-Tp"
      },
      "outputs": [],
      "source": [
        "df_cognition.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b12RXnhqV-Tp"
      },
      "source": [
        "# 2. Merging two dataframes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_rBAqFSV-Tp"
      },
      "source": [
        "For our dataset of 1206 subjects, we have information about their gender, age range and a variety of cognitive measures. It would be interesting to integrate some other data as well. You have been provided with a separate file that contains brain structure volume data obtained from the neuroimaging data of these same subjects (note that not all subjects in the HCP have neuroimaging data) (see [README](https://github.com/NadiaBlostein/McMedHacks2022_Prep_Week_3_Assignment#readme) to learn more about how volumes were obtained)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0WEmj8XV-Tp"
      },
      "outputs": [],
      "source": [
        "df_volumes = pd.read_csv(\"HCP_csv_data/HCP_volumes.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 6:** How many subjects and features does `df_volumes` have?"
      ],
      "metadata": {
        "id": "8tvCBCVslDLu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "print(f\"Num subjects: {df_volumes.shape[0]}\")\n",
        "print(f\"Num features: {df_volumes.shape[1]}\")"
      ],
      "metadata": {
        "cellView": "form",
        "collapsed": true,
        "id": "IGrxEaawlCwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 7:** Print the mean and standard deviation of total brain volume (TBV) of this sample. Note that the unit is in mm3."
      ],
      "metadata": {
        "id": "kAvipapJlXhm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_MU4Tnw5V-Tp",
        "cellView": "form",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "print(f\"Mean TBV: {df_volumes['TBV'].mean()}\")\n",
        "print(f\"TBV standard deviation: {df_volumes['TBV'].std()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M59oqzyHV-Tp"
      },
      "source": [
        "**Question 8:** List all the subjects whose TBV is above average."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sv17Js45V-Tq",
        "cellView": "form",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "df_volumes[df_volumes['TBV']>df_volumes['TBV'].mean()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63BHKuYDV-Tq"
      },
      "source": [
        "Ok! Let's merge our dataframes. One problem is that our behavioral data has 1206 subjects and our volume data has 1086 subjects. \n",
        "\n",
        "**Question 9:** Create a new dataframe called `df_final` where we only keep the subjects for which we have all of our features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bF-AXKccV-Tq",
        "collapsed": true,
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "df_final=pd.merge(df_cognition,df_volumes, on='Subject')\n",
        "df_final.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_final.shape)"
      ],
      "metadata": {
        "id": "JYLNBLnJmLcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41UPVZxeV-Tq"
      },
      "source": [
        "Mission accomplished! We have 1086 and 35 features (22 features + 12 features - `Subject` features which is shared by both dfs)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_dZ5uqOV-Tq"
      },
      "source": [
        "# 3. Removing features that you do not need"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 10:** Find and remove any duplicate columns."
      ],
      "metadata": {
        "id": "1UkGHuy8IgBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "cols_to_drop=[]\n",
        "for i in range(df_final.shape[1]):\n",
        "    for j in range(i+1,df_final.shape[1]):\n",
        "        col1=df_final.columns[i]\n",
        "        col2=df_final.columns[j]\n",
        "        if (df_final[col1].equals(df_final[col2])):\n",
        "            print(f\"Duplicate columns: {col1, col2}\")\n",
        "            cols_to_drop.append(col2)\n",
        "df_final.drop(cols_to_drop, inplace=True, axis=1)"
      ],
      "metadata": {
        "id": "BlCUoH3wJk_V",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_final.shape) "
      ],
      "metadata": {
        "id": "ykIY0AwO29no"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kk9oZn8rV-Tr"
      },
      "source": [
        "# 4. Making your data machine-readable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6p9y9UQmV-Tr"
      },
      "source": [
        "To be machine-readable, your variables need to be numerical. Want to check?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rD_Qg7vV-Tr"
      },
      "outputs": [],
      "source": [
        "df_final.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFQsnbWlV-Tr"
      },
      "source": [
        "We have 3 columns that are non-numerical: `Gender`,`Age`,`PSQI_BedTime`. Let's figure out how to handle them, one at a time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDMZGn-7V-Tr"
      },
      "source": [
        "### One-hot encoding or binarizing your data\n",
        "First, we know that the `Gender` column is categorical and has two unique values: `M` or `F`. \n",
        "\n",
        "**Question 11:** Replace all of your `M` values with 1 and `F` values with 2. Hint: `.replace()` can be quite helpful."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oa77oNphV-Tr",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "df_final['Gender'] = df_final['Gender'].replace('M',1)\n",
        "df_final['Gender'] = df_final['Gender'].replace('F',2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q22Um_pUV-Tr"
      },
      "source": [
        "**Quick note on one-hot encoding:** Suppose that you actually had more than 2 numerical values for this feature (e.g. `M`,`F`,`other`). If you just convert categorical variables to numerical values (ex: `M`=1,`F`=2,`other`=3), you give a \"distance\" to the relationship between variables. For instance, since 1 is closer to 2 than to 3, you are telling your machine that `M` is \"closer\" to `F` (`distance = 2 - 1 = 1`) than to `other` (`distance = 3 - 1 = 2`). One-hot encoding is a way to make sure the categories remain independant and we strongly suggest that you read more about it: \"[A representation of categorical variables as binary vectors](https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/)\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xuti0j5VV-Ts"
      },
      "source": [
        "### Parsing strings in your data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_Fexj30V-Ts"
      },
      "source": [
        "#### Handling the `Age` feature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGTxCDCvV-Ts"
      },
      "source": [
        "Remember that our `Age` feature is also non-numerical!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMaLuwlPV-Ts"
      },
      "outputs": [],
      "source": [
        "df_final['Age'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6izSxt7eV-Ts"
      },
      "source": [
        "For the sake of this exercise, let's replace 36+ with a range of 36-40."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final['Age'] = df_final['Age'].replace(\"36+\",'36-40')\n",
        "df_final['Age'].value_counts()"
      ],
      "metadata": {
        "id": "1GlY65tn4a0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our age range values are organized very clearly: `minimum ageâ€“maximum age`. These age range strings can therefore be split around the `-` such that you create two new columns: one for `minimum age` and one for `maximum age`."
      ],
      "metadata": {
        "id": "qSWS24gl4bOz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWGKnhdcV-Ts"
      },
      "outputs": [],
      "source": [
        "fix_age = df_final['Age'].str.split('-', 1, expand=True)\n",
        "fix_age.columns = ['min','max']\n",
        "fix_age[\"min\"] = fix_age['min'].astype(float)\n",
        "fix_age[\"max\"] = fix_age['max'].astype(float)\n",
        "fix_age"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 12:** Using the code in the cell above, replace the age range string for each subject with the mean of the subject's respective age range."
      ],
      "metadata": {
        "id": "EpPpU5DQnfq9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uwor8DLqV-Ts",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "fix_age['mean'] = (fix_age['max']+fix_age['min'])/2\n",
        "df_final['Age'] = fix_age['mean']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final.head(3)"
      ],
      "metadata": {
        "id": "PyE6rGXV4tm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ks8toV84V-Ts"
      },
      "source": [
        "#### Handling the `PSQI_BedTime` feature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hs_CxE3HV-Ts"
      },
      "source": [
        "Convert your bed time variable from HH:MM:SS to seconds! You can walk through the code to figure out what each step does.\n",
        "`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "Bnziq-1QV-Tt"
      },
      "outputs": [],
      "source": [
        "ftr = [3600,60,1]\n",
        "for i in range(len(df_final['PSQI_BedTime'])):\n",
        "    x = sum([a*b for a,b in zip(ftr, map(int,df_final['PSQI_BedTime'][i].split(':')))])\n",
        "    df_final['PSQI_BedTime'][i] = x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjuGPr07V-Tt"
      },
      "source": [
        "#### A note on other strings that often crop up in dataframes and need to be replaced with numbers!\n",
        "`df_final = df_final.replace('FALSE',0)` \\\n",
        "`df_final = df_final.replace('TRUE',1)` \\\n",
        "`df_final = df_final.replace(False,0)` \\\n",
        "`df_final = df_final.replace(True,1)` \\\n",
        "`df_final = df_final.replace('0',0)` # example of random spaces \\\n",
        "`df_final = df_final.replace(' ',np.NaN)` # example of random spaces"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQenax9dV-Tt"
      },
      "source": [
        "**Question 13:** Write a code that makes sure that every column is of type float!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "qu2IPUdZV-Tt",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "for col in df_final.columns:\n",
        "    df_final[col] = df_final[col].astype(float)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FP_h6HlKV-Tt"
      },
      "source": [
        "# 5. Handling not available (NA) and inf data:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfiQZysiV-Tt"
      },
      "source": [
        "Sometimes, Python will convert some of your values to + or - infinity, which will result in downstream errors. Convert them to NA, and then handle them as NA values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXTXFDNVV-Tt"
      },
      "outputs": [],
      "source": [
        "df_final = df_final.replace([np.inf, -np.inf], np.nan)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QX2xgJzkV-Tt"
      },
      "source": [
        "Next, you need to deal with your NA values. \n",
        "\n",
        "**Question 14:** How many nas do you have?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RF_6bB7wV-Tt",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "df_final.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKCftVkdV-Tt"
      },
      "source": [
        "There is a variety of ways to handle NA data. The most simple approach is to replace NA data with the median (or mean) value of the feature of interest. There are [other](https://towardsdatascience.com/6-different-ways-to-compensate-for-missing-values-data-imputation-with-examples-6022d9ca0779) [more](https://arxiv.org/abs/1804.11087) sophisticated data imputation techniques out there, many of which actually leverage machine learning tools (so meta)!\n",
        "\n",
        "**Question 15:** Replace the NA values of this dataframe with the feature-specific median (the median is more robust against outliers than the mean is)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lad9NHw9V-Tt",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "for col in df_final.columns:\n",
        "    df_final[col].fillna(df_final[col].median(), inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9RH8R3LV-Tu"
      },
      "outputs": [],
      "source": [
        "df_final.isna().sum().sum()\n",
        "# note the difference between df_final.isna().sum() and df_final.isna().sum().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qZ-YOcWV-Tu"
      },
      "source": [
        "# 6. Data visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzQT3zchV-Tu"
      },
      "source": [
        "Data visualization is a wonderful way to get to know your data in order to plan a relevant analysis or find an appropriate machine learning application. [Matplotlib](https://matplotlib.org/) and [seaborn](https://seaborn.pydata.org/) are two canonical data visualization tools that you can use in Python."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_L_6wczKV-Tu"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fekJR587V-Tv"
      },
      "source": [
        "#### Scatter plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOwRnWU2V-Tv"
      },
      "outputs": [],
      "source": [
        "plt.rcParams[\"figure.figsize\"] = (10,5) # adjust figure size\n",
        "plt.scatter(df_final[\"PSQI_BedTime\"],df_final[\"TBV\"]) # plt.scatter(x, y)\n",
        "plt.ylabel(\"TBV (mm3)\") # name y-axis\n",
        "plt.xlabel(\"Bedtime (seconds)\") # name x-axis\n",
        "plt.title(\"Total brain volume (TBV) as a function of bed time\") # figure title"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 16:** Make a scatter plot of total brain volume (TBV) as a function of bed time, by gender."
      ],
      "metadata": {
        "id": "KGmR_x-Aq-QB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "plt.rcParams[\"figure.figsize\"] = (10,5) # adjust figure size\n",
        "plt.scatter(df_final[\"PSQI_BedTime\"][df_final[\"Gender\"]==2],df_final[\"TBV\"][df_final[\"Gender\"]==2],color='turquoise')\n",
        "    # plot female datapoints first, in turquoise\n",
        "plt.scatter(df_final[\"PSQI_BedTime\"][df_final[\"Gender\"]==1],df_final[\"TBV\"][df_final[\"Gender\"]==1],color='coral')\n",
        "    # plot female datapoints first, in coral\n",
        "plt.ylabel(\"TBV (mm3)\") # name y-axis\n",
        "plt.xlabel(\"Bedtime (seconds)\") # name x-axis\n",
        "plt.title(\"Total brain volume (TBV) as a function of bed time, by gender\") # figure title\n",
        "plt.legend(['Females','Males']) # legend"
      ],
      "metadata": {
        "cellView": "form",
        "id": "BFqw3-FtqbrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhLbR9ZlV-Tw"
      },
      "source": [
        "#### Histogram plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwQf03YAV-Tx"
      },
      "outputs": [],
      "source": [
        "sns.displot(df_final,x='TBV',kind='kde',fill=True) # plot your histogram\n",
        "plt.ylabel(\"Density\") # name y-axis\n",
        "plt.xlabel(\"TBV (mm3)\") # name x-axis\n",
        "plt.title(\"Distribution of total brain volume (TBV) in our sample\") # figure title\n",
        "plt.gcf().set_size_inches(8, 5) # another way to adjust figure size"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final.columns"
      ],
      "metadata": {
        "id": "IO44Kuo-9W3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTA7DWybV-Tx"
      },
      "outputs": [],
      "source": [
        "sns.histplot(df_final,x='Str_Left',fill=True,color='orange')\n",
        "    # first, plot the distribution of the left striatum in orange\n",
        "sns.histplot(df_final,x='Thal_Left',fill=True,color='turquoise')\n",
        "    # second, plot the distribution of the left thalamus volume in turquoise\n",
        "plt.legend(['Left striatum','Left thalamus'])\n",
        "plt.ylabel(\"Density\")\n",
        "plt.xlabel(\"Structure-specific volume (mm3)\")\n",
        "plt.title(\"Distribution of different structure volumes in our sample\")\n",
        "plt.gcf().set_size_inches(8, 5) # adjust figure size\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 17:** Generate two smoothed and superimposed histograms of bed times in subjects that are above and below 30 years."
      ],
      "metadata": {
        "id": "nvaFPk-5rUrw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "df_final[\"Over 25 years\"]=df_final[\"Age\"]>25\n",
        "sns.displot(df_final,x='TBV',hue='Over 25 years',kind='kde',fill=True)\n",
        "plt.ylabel(\"Density\")\n",
        "plt.xlabel(\"TBV (mm3)\")\n",
        "plt.title(\"Distribution of total brain volume (TBV) in our sample for people who are below and above 25 years of age\")\n",
        "plt.gcf().set_size_inches(14, 6) "
      ],
      "metadata": {
        "id": "ju817ns-rV7V",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that brains seem to shrink with age in our dataset... Let's look at the numbers:"
      ],
      "metadata": {
        "id": "-7kKZDlFsTlV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TBV_below_25=df_final['TBV'][df_final[\"Age\"]<=25].mean()\n",
        "TBV_above_25=df_final['TBV'][df_final[\"Age\"]>25].mean()\n",
        "print(f\"Average TBV for people below or equal to 25 years of age: {round(TBV_below_25,0)} mm3\") \n",
        "print(f\"Average TBV for people above 25 years of age: {round(TBV_above_25,0)} mm3\")"
      ],
      "metadata": {
        "id": "iviSqsSXtFMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interesting! However, does our sample actually have a similar amout of people who are below and above the age of 25? \n",
        "\n",
        "**Question 18:** Count how many people are <= 25 years, and how many people are > 25 yrs."
      ],
      "metadata": {
        "id": "n7mhDCIFtdBi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subj_above_25=df_final[df_final[\"Age\"]>25].shape[0]\n",
        "subj_below_25=df_final[df_final[\"Age\"]<=25].shape[0]\n",
        "print(f\"We have {subj_below_25} subjects below or at 25 years of age and {subj_above_25} subjects above 25 years of age.\")"
      ],
      "metadata": {
        "id": "KF6kiQdPtrdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. 2D image visualization\n",
        "Let's visualize the `.png` files that come with this repository. We can do this by opening the image with the `PIL.Image` module seen in the previous lectures/assigments."
      ],
      "metadata": {
        "id": "n2uLV6uiXedo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the image as an array\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Try changing the \n",
        "png_file_path = os.path.join(\"HCP_2D_slices_MRI_data\", \"HCP_102109_T1w_acpc_dc_restore_brain_t1_axial.png\")\n",
        "png_array = np.array(Image.open(png_file_path))"
      ],
      "metadata": {
        "id": "E0QwzsTeXnYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's inspect the `png_array` object. The `Image.open` method opens the `.png` as a numpy array, so we can use all the `numpy` array methods on it. "
      ],
      "metadata": {
        "id": "qCtdhWxoV5hG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Qusetion 19:** Create a function `plot_png_array` which takes as parameters a list of `png_array`'s, a `title` and the figure size `figsize`. Hint: Look at the previous week's assignment and plots each element of the array as a grayscale."
      ],
      "metadata": {
        "id": "wUyk-DYEXYas"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function that plots a *list* of numpy arrays in grayscale\n",
        "def plot_png_array(png_array_list, title, figsize=(10, 10)):\n",
        "  for png_array in png_array_list:\n",
        "    # Plot the image with imgshow\n",
        "    fg, ax = plt.subplots(figsize=(10, 10))\n",
        "\n",
        "    ax.imshow(png_array, cmap='gray')\n",
        "\n",
        "    ax.set_title(title)\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "LIg1gE1EemDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the function you just created to plot the `png_array` assigned above."
      ],
      "metadata": {
        "id": "SyqJA-KjY9LO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_png_array([png_array,], \"Brain\")"
      ],
      "metadata": {
        "id": "hUHtnx4XZE11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inspect the following code. What do you think the `reduce_png_array_dim` does?"
      ],
      "metadata": {
        "id": "P8c8oQv5h64d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def reduce_png_array_dim(png_array, kernel_height=2, kernel_width=2):\n",
        "  cropped_png_array = []\n",
        "  for channel_idx in range(0, png_array.shape[-1]):\n",
        "    cropped_channel_png_array = []\n",
        "    for i in range(0, png_array.shape[0], kernel_height):\n",
        "      cropped_array = []\n",
        "      for j in range(0, png_array.shape[1], kernel_width):\n",
        "        cropped_array.append(png_array[i:i+kernel_height, j:j+kernel_width, channel_idx].mean())\n",
        "      cropped_channel_png_array.append(cropped_array)\n",
        "    cropped_channel_png_array = np.array(cropped_channel_png_array)\n",
        "    cropped_png_array.append(cropped_channel_png_array)\n",
        "  cropped_png_array = np.array(cropped_png_array)\n",
        "  # Numpy shape fix + convert to integer\n",
        "  return np.moveaxis(cropped_png_array, 0, -1).astype(np.int32)"
      ],
      "metadata": {
        "id": "7CWRrZNfeo-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cropped_png_array = reduce_png_array_dim(png_array)"
      ],
      "metadata": {
        "id": "2WvUSHhsmDfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hint: Look at the input before and after `reduce_png_array_dim`. What do you observe in terms of the "
      ],
      "metadata": {
        "id": "9ur939qaio9b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replot the original and cropped image\n",
        "plot_png_array([png_array, cropped_png_array], \"Brain\")"
      ],
      "metadata": {
        "id": "oJtYcI3ze0RO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Week0-3_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}